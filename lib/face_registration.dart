import 'dart:async';
import 'dart:convert';
import 'dart:math' as math;
import 'package:flutter/material.dart';
import 'package:camera/camera.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'cabinet_selection.dart';
import 'embeddings/face_embedder.dart';
import 'face_detection/camera_view.dart';
import 'face_detection/face_detector_painter.dart';
import 'services/model_manager.dart';
import 'management/utility_login.dart';
import 'management/login.dart';

class FaceRegistrationScreen extends StatefulWidget {
  final List<CameraDescription> cameras;
  const FaceRegistrationScreen({super.key, required this.cameras});

  @override
  FaceRegistrationScreenState createState() => FaceRegistrationScreenState();
}

class FaceRegistrationScreenState extends State<FaceRegistrationScreen> {
  // Camera reference
  final GlobalKey<CameraViewState> _cameraKey = GlobalKey<CameraViewState>();

  // Face Detection
  late FaceDetector _faceDetector;
  bool _isFaceDetectorInitialized = false;
  CustomPaint? _customPaint;
  bool _isBusy = false;
  // UI State
  String? _selectedCabinetId;
  String _instruction = 'Nh√¨n v√†o camera';
  bool _isScanningActive = false;
  int _captureCount = 0;
  static const int _requiredCaptureCount = 5;
  List<XFile> _capturedImages = [];
  Timer? _scanTimer;

  // S·ª≠ d·ª•ng AIModelManager thay v√¨ kh·ªüi t·∫°o ri√™ng
  FaceEmbedder? get _faceEmbedder => AIModelManager.instance.faceEmbedder;
  bool get _isEmbedderInitialized => _faceEmbedder?.isModelLoaded ?? false;
  bool get _modelLoaded => AIModelManager.instance.isInitialized;

  // Processing state
  bool _isProcessing = false;

  // Backup completion check
  Timer? _completionCheckTimer;

  // Processing progress tracking
  int _processedImageCount = 0;
  double _processingProgress = 0.0;
  String _processingStatus = '';

  // Face Quality-based Capture
  int _consecutiveGoodFrames = 0; // S·ªë frames t·ªët li√™n ti·∫øp
  static const int _requiredGoodFrames = 3; // C·∫ßn 3 frames t·ªët ƒë·ªÉ trigger
  Face? _bestFace; // Face t·ªët nh·∫•t trong window
  double _bestQualityScore = 0.0; // ƒêi·ªÉm ch·∫•t l∆∞·ª£ng cao nh·∫•t
  Timer?
  _qualityResetTimer; // Timer reset quality sau th·ªùi gian kh√¥ng ho·∫°t ƒë·ªông

  final List<Cabinet> _cabinets = List.generate(
    16,
    (i) => Cabinet(id: 'T·ªß ${i + 1}'),
  );
  @override
  void initState() {
    super.initState();
    _initFaceDetector();
  }

  // Ng∆∞·ª°ng k√≠ch th∆∞·ªõc khu√¥n m·∫∑t t·ªëi thi·ªÉu (t·ª∑ l·ªá v·ªõi chi·ªÅu r·ªông ·∫£nh)
  static const double _minFaceSize = 0.1;

  /// Kh·ªüi t·∫°o Face Detector
  Future<void> _initFaceDetector() async {
    try {
      _faceDetector = FaceDetector(
        options: FaceDetectorOptions(
          enableContours: false,
          enableClassification: false,
          minFaceSize: _minFaceSize,
          performanceMode: FaceDetectorMode.accurate,
          enableLandmarks: false,
        ),
      );

      if (mounted) {
        setState(() {
          _isFaceDetectorInitialized = true;
        });
      }
    } catch (e) {
      // Error initializing Face Detector
    }
  }

  /// X·ª≠ l√Ω h√¨nh ·∫£nh t·ª´ camera ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t - ENHANCED v·ªõi quality assessment
  Future<void> _processImage(InputImage inputImage) async {
    if (_isBusy) return;
    _isBusy = true;

    try {
      final faces = await _faceDetector.processImage(inputImage);

      if (inputImage.metadata?.size != null &&
          inputImage.metadata?.rotation != null) {
        final painter = FaceDetectorPainter(
          faces,
          inputImage.metadata!.size,
          inputImage.metadata!.rotation,
        );
        _customPaint = CustomPaint(painter: painter);

        // Enhanced instruction d·ª±a tr√™n quality assessment
        if (faces.isEmpty) {
          _consecutiveGoodFrames = 0;
          _bestFace = null;
          _bestQualityScore = 0.0;
          _instruction = 'Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t - H√£y nh√¨n v√†o camera';
        } else if (faces.length == 1) {
          final face = faces.first;
          final qualityScore = _calculateFaceQuality(face, inputImage);

          // Quality-based instruction updates - GI·∫¢M XU·ªêNG 75% (kh√¥ng c·∫ßn center position)
          if (qualityScore >= 0.75) {
            // T·ª´ 0.8 ‚Üí 0.75 (75%)
            _consecutiveGoodFrames++;

            // Track best face trong window
            if (qualityScore > _bestQualityScore) {
              _bestFace = face;
              _bestQualityScore = qualityScore;
            }

            if (!_isScanningActive) {
              _instruction =
                  '‚úÖ Ch·∫•t l∆∞·ª£ng t·ªët (${(qualityScore * 100).toInt()}%) - '
                  '·ªîn ƒë·ªãnh ${_consecutiveGoodFrames}/$_requiredGoodFrames - S·∫µn s√†ng ƒëƒÉng k√Ω';
            } else {
              _instruction =
                  '‚úÖ ƒêang ch·ª•p v·ªõi ch·∫•t l∆∞·ª£ng t·ªët (${(qualityScore * 100).toInt()}%)';
            }
          } else if (qualityScore >= 0.6) {
            // T·ª´ 0.65 ‚Üí 0.6 (60%)
            _consecutiveGoodFrames = 0; // Reset counter for medium quality
            _instruction =
                '‚ö†Ô∏è Ch·∫•t l∆∞·ª£ng kh√° (${(qualityScore * 100).toInt()}%) - C·∫ßn c·∫£i thi·ªán ƒë·ªÉ ƒë·∫°t 75%';
          } else {
            _consecutiveGoodFrames = 0; // Reset counter

            // Specific feedback - B·ªé CENTER POSITION, N·ªöI L·ªéNG cho 75%
            final imageSize = inputImage.metadata!.size;
            final faceRatio = face.boundingBox.width / imageSize.width;

            if (faceRatio < 0.15) {
              // N·ªõi l·ªèng: 0.18 ‚Üí 0.15
              _instruction =
                  'üìè Khu√¥n m·∫∑t qu√° nh·ªè - ƒê·∫øn g·∫ßn camera h∆°n (c·∫ßn √≠t nh·∫•t 15% khung h√¨nh)';
            } else if (faceRatio > 0.8) {
              // N·ªõi l·ªèng: 0.75 ‚Üí 0.8
              _instruction =
                  'üìè Khu√¥n m·∫∑t qu√° l·ªõn - L√πi xa camera m·ªôt ch√∫t (t·ªëi ƒëa 80% khung h√¨nh)';
            } else if (face.headEulerAngleY!.abs() > 18) {
              // N·ªõi l·ªèng: 12 ‚Üí 18
              _instruction =
                  'üîÑ H√£y nh√¨n th·∫≥ng v√†o camera (g√≥c ngang: ${face.headEulerAngleY!.toInt()}¬∞ > 18¬∞)';
            } else if (face.headEulerAngleZ!.abs() > 18) {
              // N·ªõi l·ªèng: 12 ‚Üí 18
              _instruction =
                  'üîÑ H√£y gi·ªØ ƒë·∫ßu th·∫≥ng (g√≥c nghi√™ng: ${face.headEulerAngleZ!.toInt()}¬∞ > 18¬∞)';
            } else if (face.landmarks.isEmpty) {
              _instruction =
                  'üëÅÔ∏è Kh√¥ng ph√°t hi·ªán landmarks - C·∫ßn √°nh s√°ng t·ªët h∆°n';
            } else if (!face.landmarks.containsKey(FaceLandmarkType.leftEye) ||
                !face.landmarks.containsKey(FaceLandmarkType.rightEye)) {
              _instruction =
                  'üëÅÔ∏è Kh√¥ng ph√°t hi·ªán ƒë·∫ßy ƒë·ªß landmarks m·∫Øt - C·∫ßn r√µ r√†ng h∆°n';
            } else {
              _instruction =
                  '‚ùå Ch·∫•t l∆∞·ª£ng ch∆∞a ƒë·∫°t 75% (${(qualityScore * 100).toInt()}%) - C·∫£i thi·ªán v·ªã tr√≠ v√† √°nh s√°ng';
            }
          }

          // Auto-reset quality tracking n·∫øu kh√¥ng c√≥ ho·∫°t ƒë·ªông trong 3 gi√¢y
          _qualityResetTimer?.cancel();
          _qualityResetTimer = Timer(const Duration(seconds: 3), () {
            if (!_isScanningActive) {
              _resetQualityTracking();
              if (mounted) {
                setState(() {
                  _instruction =
                      'Nh√¨n v√†o camera ƒë·ªÉ b·∫Øt ƒë·∫ßu ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng (c·∫ßn 75%)';
                });
              }
            }
          });
        } else {
          _consecutiveGoodFrames = 0;
          _bestFace = null;
          _bestQualityScore = 0.0;
          _instruction =
              'Ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t - Ch·ªâ m·ªôt ng∆∞·ªùi trong khung h√¨nh';
        }
      } else {
        _customPaint = null;
        _instruction = 'ƒêang kh·ªüi t·∫°o camera...';
      }
    } catch (e) {
      _customPaint = null;
      _instruction = 'L·ªói x·ª≠ l√Ω h√¨nh ·∫£nh';
      _consecutiveGoodFrames = 0;
    }

    _isBusy = false;
    if (mounted) {
      setState(() {});
    }
  }

  /// Callback khi capture h√¨nh ·∫£nh - CH·ªà D√ôNG ƒê·ªÇ LOG, KH√îNG TH√äM V√ÄO LIST
  void _onImageCaptured(XFile image) {
    // Kh√¥ng th√™m v√†o _capturedImages ·ªü ƒë√¢y ƒë·ªÉ tr√°nh duplicate
    // _capturedImages s·∫Ω ƒë∆∞·ª£c qu·∫£n l√Ω trong _captureAndProcessImage
  }

  /// B·∫Øt ƒë·∫ßu ƒëƒÉng k√Ω khu√¥n m·∫∑t
  void _startFaceRegistration() {
    if (_selectedCabinetId == null) {
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(
          content: Text('Vui l√≤ng ch·ªçn t·ªß v√† nh·∫≠p t√™n tr∆∞·ªõc khi ƒëƒÉng k√Ω'),
        ),
      );
      return;
    }

    if (!_modelLoaded) {
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(content: Text('ƒêang t·∫£i m√¥ h√¨nh, vui l√≤ng ƒë·ª£i...')),
      );
      return;
    }

    setState(() {
      _capturedImages.clear(); // Clear any existing images
      _captureCount = 0; // Reset counter
      _isScanningActive = true;
      _instruction = 'Chu·∫©n b·ªã ch·ª•p ·∫£nh...';
    });

    // B·∫Øt ƒë·∫ßu qu√° tr√¨nh ch·ª•p ·∫£nh sau 2 gi√¢y (gi·∫£m t·ª´ 3 gi√¢y)
    Timer(const Duration(seconds: 2), _startCaptureSequence);
  }

  /// B·∫Øt ƒë·∫ßu chu·ªói ch·ª•p ·∫£nh - ENHANCED v·ªõi quality-based capture - N√ÇNG L√äN 80%
  void _startCaptureSequence() {
    if (!_isScanningActive) return;

    _scanTimer = Timer.periodic(const Duration(milliseconds: 800), (
      timer,
    ) async {
      // TƒÉng interval t·ª´ 700ms ‚Üí 800ms
      // Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng tr∆∞·ªõc khi th·ª±c hi·ªán b·∫•t k·ª≥ thao t√°c n√†o
      if (_captureCount >= _requiredCaptureCount || !_isScanningActive) {
        timer.cancel();

        // Ch·ªâ g·ªçi _completeRegistration n·∫øu ƒë√£ ƒë·ªß s·ªë l∆∞·ª£ng v√† v·∫´n ƒëang scanning
        if (_captureCount >= _requiredCaptureCount &&
            _isScanningActive &&
            !_isProcessing) {
          await _completeRegistration();
        }
        return;
      }

      // ‚úÖ CH·ªà CH·ª§P KHI CH·∫§T L∆Ø·ª¢NG T·ªêT V√Ä ·ªîN ƒê·ªäNH - N√ÇNG L√äN 80%
      if (_consecutiveGoodFrames >= _requiredGoodFrames &&
          _bestQualityScore >= 0.75) {
        print(
          "üéØ High quality capture for registration (no center required): Score=${_bestQualityScore.toStringAsFixed(3)}, "
          "Consecutive=${_consecutiveGoodFrames}",
        );

        await _captureAndProcessImage();

        // Reset quality tracking after successful capture ƒë·ªÉ t√¨m frame t·ªët ti·∫øp theo
        _consecutiveGoodFrames = 0;
        _bestQualityScore = 0.0;
        _bestFace = null;

        // Delay d√†i h∆°n ƒë·ªÉ camera ·ªïn ƒë·ªãnh tr∆∞·ªõc l·∫ßn ch·ª•p ti·∫øp theo
        await Future.delayed(
          const Duration(milliseconds: 600),
        ); // TƒÉng t·ª´ 500ms ‚Üí 700ms
      } else {
        // Wait for better quality v·ªõi detailed feedback - N√ÇNG L√äN 80%
        final qualityPercent = (_bestQualityScore * 100).toInt();
        setState(() {
          if (_bestQualityScore > 0) {
            _instruction =
                'ƒêang ch·ªù ch·∫•t l∆∞·ª£ng xu·∫•t s·∫Øc... '
                '(Hi·ªán t·∫°i: ${qualityPercent}%, '
                '·ªîn ƒë·ªãnh: $_consecutiveGoodFrames/$_requiredGoodFrames)';
          } else {
            _instruction =
                'ƒêang t√¨m ki·∫øm khu√¥n m·∫∑t ch·∫•t l∆∞·ª£ng xu·∫•t s·∫Øc (‚â•80%) ƒë·ªÉ ch·ª•p...';
          }
        });
      }
    });
  }

  /// Ch·ª•p v√† x·ª≠ l√Ω ·∫£nh - ENHANCED v·ªõi optimal timing
  Future<void> _captureAndProcessImage() async {
    if (!_isScanningActive || _captureCount >= _requiredCaptureCount) return;

    setState(() {
      _instruction =
          'ƒêang ch·ª•p ·∫£nh ch·∫•t l∆∞·ª£ng cao ${_captureCount + 1}/$_requiredCaptureCount...';
    });

    try {
      // Wait for camera stabilization after quality detection
      await Future.delayed(const Duration(milliseconds: 200));

      // Ki·ªÉm tra l·∫°i tr∆∞·ªõc khi ch·ª•p ƒë·ªÉ tr√°nh race condition
      if (!_isScanningActive || _captureCount >= _requiredCaptureCount) return;

      // Capture image from camera using GlobalKey with timeout
      if (_cameraKey.currentState != null && _bestFace != null) {
        XFile? capturedImage;

        try {
          // Add timeout for image capture
          capturedImage = await Future.any([
            _cameraKey.currentState!.takePicture(),
            Future.delayed(
              const Duration(seconds: 5),
              () => throw Exception('Camera capture timeout'),
            ),
          ]);
        } catch (e) {
          setState(() {
            _instruction = 'L·ªói ch·ª•p ·∫£nh - Th·ª≠ l·∫°i trong gi√¢y l√°t';
          });
          return;
        }

        if (capturedImage != null && _captureCount < _requiredCaptureCount) {
          // Enhanced validation v·ªõi quality-based capture
          bool isValidImage = await _validateCapturedImageWithOptimalFace(
            capturedImage,
            _captureCount,
            _bestFace!,
          );

          if (isValidImage) {
            // Double check before adding to avoid exceeding limit
            if (_capturedImages.length < _requiredCaptureCount) {
              _capturedImages.add(capturedImage);
              _captureCount++;

              setState(() {
                _instruction =
                    'ƒê√£ ch·ª•p $_captureCount/$_requiredCaptureCount ·∫£nh ch·∫•t l∆∞·ª£ng cao '
                    '(Quality: ${(_bestQualityScore * 100).toInt()}%)';
              });
            }
          } else {
            // Even with quality checks, accept the image to avoid infinite loop
            if (_capturedImages.length < _requiredCaptureCount) {
              _capturedImages.add(capturedImage);
              _captureCount++;

              setState(() {
                _instruction =
                    'ƒê√£ ch·ª•p $_captureCount/$_requiredCaptureCount ·∫£nh (ch·∫•t l∆∞·ª£ng acceptable)';
              });
            }
          }

          // Ki·ªÉm tra v√† d·ª´ng timer ngay khi ƒë·∫°t ƒë·ªß s·ªë l∆∞·ª£ng
          if (_captureCount >= _requiredCaptureCount) {
            _scanTimer?.cancel();
            setState(() {
              _instruction = 'ƒêang x·ª≠ l√Ω d·ªØ li·ªáu ch·∫•t l∆∞·ª£ng cao...';
            });

            // G·ªçi _completeRegistration() ngay l·∫≠p t·ª©c n·∫øu ch∆∞a ƒëang x·ª≠ l√Ω
            if (!_isProcessing) {
              await _completeRegistration();
            }

            // Backup timer ƒë·ªÉ ƒë·∫£m b·∫£o completion ƒë∆∞·ª£c g·ªçi
            _completionCheckTimer = Timer(const Duration(seconds: 2), () {
              if (_captureCount >= _requiredCaptureCount &&
                  !_isProcessing &&
                  _isScanningActive) {
                _completeRegistration();
              }
            });
          }
        } else {
          throw Exception('Failed to capture image or capture limit reached');
        }
      } else {
        throw Exception('Camera not ready or no optimal face detected');
      }
    } catch (e) {
      setState(() {
        _instruction = 'L·ªói ch·ª•p ·∫£nh - Th·ª≠ l·∫°i';
      });
    }
  }

  /// Ho√†n th√†nh ƒëƒÉng k√Ω
  Future<void> _completeRegistration() async {
    if (_isProcessing) {
      return; // Tr√°nh x·ª≠ l√Ω tr√πng l·∫∑p
    }

    // Final validation of image count
    if (_capturedImages.length > _requiredCaptureCount) {
      _capturedImages = _capturedImages.take(_requiredCaptureCount).toList();
    }

    _isProcessing = true;
    setState(() {
      _instruction = 'ƒêang x·ª≠ l√Ω v√† l∆∞u d·ªØ li·ªáu...';
    });

    try {
      // Save registration data immediately without delay
      await _saveFaceData();

      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(
            content: Text(
              'ƒêƒÉng k√Ω khu√¥n m·∫∑t cho $_selectedCabinetId th√†nh c√¥ng',
            ),
          ),
        );
      }

      setState(() {
        _isScanningActive = false;
        _instruction = 'ƒêƒÉng k√Ω th√†nh c√¥ng!';
      });
    } catch (e) {
      setState(() {
        _isScanningActive = false;
        _instruction = 'L·ªói ƒëƒÉng k√Ω: $e';
      });

      if (mounted) {
        ScaffoldMessenger.of(
          context,
        ).showSnackBar(SnackBar(content: Text('L·ªói ƒëƒÉng k√Ω: $e')));
      }
    } finally {
      _isProcessing = false;
    }
  }

  /// L∆∞u d·ªØ li·ªáu khu√¥n m·∫∑t v·ªõi x·ª≠ l√Ω ƒëa lu·ªìng
  Future<void> _saveFaceData() async {
    if (_capturedImages.isEmpty) {
      throw Exception('Kh√¥ng c√≥ ·∫£nh ƒë·ªÉ x·ª≠ l√Ω');
    }

    // Log s·ªë l∆∞·ª£ng ·∫£nh th·ª±c t·∫ø
    if (_capturedImages.length != _requiredCaptureCount) {
      // Warning: image count mismatch
    }

    final prefs = await SharedPreferences.getInstance();

    try {
      final stopwatch = Stopwatch()..start();

      // Update UI to show processing status
      setState(() {
        _processingStatus =
            'ƒêang x·ª≠ l√Ω ${_capturedImages.length} ·∫£nh v·ªõi batch processing...';
        _processingProgress = 0.0;
        _processedImageCount = 0;
      });

      // Use batch processing for better performance and memory management
      final List<List<double>> embeddings = await _processImagesBatch(
        _capturedImages,
      );

      // Validate embeddings count
      if (embeddings.length > _requiredCaptureCount) {
        // Trim to expected count
        embeddings.removeRange(_requiredCaptureCount, embeddings.length);
      }

      stopwatch.stop();

      // Update UI to show completion
      setState(() {
        _processingStatus =
            'Ho√†n th√†nh x·ª≠ l√Ω! ƒêang t√≠nh to√°n embedding trung b√¨nh...';
        _processingProgress = 0.9;
      });

      if (embeddings.isEmpty) {
        throw Exception('Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong c√°c ·∫£nh ƒë√£ ch·ª•p');
      }

      // Calculate average embedding (for multiple images)
      final embeddingSize = 192; // MobileFaceNet embedding size
      List<double> avgEmbedding = List.filled(embeddingSize, 0.0);
      for (var embedding in embeddings) {
        for (int i = 0; i < embeddingSize; i++) {
          avgEmbedding[i] += embedding[i];
        }
      }
      for (int i = 0; i < embeddingSize; i++) {
        avgEmbedding[i] /= embeddings.length;
      }

      // Save face data
      final faceData = {
        'cabinet_id': _selectedCabinetId,
        'timestamp': DateTime.now().millisecondsSinceEpoch,
        'embedding': avgEmbedding,
        'image_count': _capturedImages.length,
        'face_count': embeddings.length,
      };

      await prefs.setString(
        'face_data_$_selectedCabinetId',
        jsonEncode(faceData),
      );

      // Save image paths for reference
      List<String> imagePaths = _capturedImages.map((img) => img.path).toList();
      await prefs.setStringList('face_images_$_selectedCabinetId', imagePaths);

      // Final UI update
      setState(() {
        _processingStatus = 'Ho√†n th√†nh! ƒê√£ l∆∞u d·ªØ li·ªáu th√†nh c√¥ng.';
        _processingProgress = 1.0;
      });
    } catch (e) {
      setState(() {
        _processingStatus = 'L·ªói x·ª≠ l√Ω: $e';
        _processingProgress = 0.0;
      });
      rethrow;
    }
  }

  /// Process individual image for embedding extraction in parallel
  Future<List<double>> _processImageForEmbeddingParallel(
    XFile imageFile,
    int imageIndex,
  ) async {
    try {
      // Create InputImage from file path (correct way for captured images)
      final inputImage = InputImage.fromFilePath(imageFile.path);

      // Detect faces
      final faces = await _faceDetector.processImage(inputImage);
      if (faces.isNotEmpty) {
        // Use the first detected face for embedding extraction
        final face = faces.first;
        final faceBox = face.boundingBox;
        // Extract face embedding using FaceEmbedder
        // ƒê·∫£m b·∫£o models ƒë√£ s·∫µn s√†ng
        await AIModelManager.instance.ensureModelsReady();

        if (_faceEmbedder != null) {
          final embeddingResult = await _faceEmbedder!.getFaceEmbedding(
            imageFile.path,
            faceBox,
          );

          if (embeddingResult.success) {
            return embeddingResult.embedding;
          } else {
            throw Exception(
              'Failed to extract face embedding from image ${imageIndex + 1}: ${embeddingResult.error}',
            );
          }
        } else {
          throw Exception(
            'FaceEmbedder not initialized for image ${imageIndex + 1}',
          );
        }
      } else {
        throw Exception('No face detected in image ${imageIndex + 1}');
      }
    } catch (e) {
      rethrow; // Re-throw the original error instead of using placeholder
    }
  }

  /// Enhanced validation v·ªõi optimal face information - GI·∫¢M XU·ªêNG 75% (B·ªé CENTER)
  Future<bool> _validateCapturedImageWithOptimalFace(
    XFile imageFile,
    int imageIndex,
    Face optimalFace,
  ) async {
    try {
      // Use the optimal face information for validation
      final faceBox = optimalFace.boundingBox;
      final inputImage = InputImage.fromFilePath(imageFile.path);
      final imageSize = inputImage.metadata?.size;

      if (imageSize == null) return false;

      // Quality checks based on optimal face - GI·∫¢M XU·ªêNG 75%
      final faceRatio = faceBox.width / imageSize.width;

      // N·ªõi l·ªèng quality requirements cho registration 75%
      if (faceRatio < 0.15 || faceRatio > 0.8)
        return false; // N·ªõi l·ªèng: 0.18-0.75 ‚Üí 0.15-0.8

      // Head pose validation v·ªõi n·ªõi l·ªèng thresholds
      if (optimalFace.headEulerAngleY != null &&
          optimalFace.headEulerAngleY!.abs() > 20.0)
        return false; // N·ªõi l·ªèng: 15.0 ‚Üí 20.0
      if (optimalFace.headEulerAngleZ != null &&
          optimalFace.headEulerAngleZ!.abs() > 18.0)
        return false; // N·ªõi l·ªèng: 12.0 ‚Üí 18.0

      // B·ªé CENTER POSITION VALIDATION HO√ÄN TO√ÄN
      // Kh√¥ng c·∫ßn ki·ªÉm tra v·ªã tr√≠ center n·ªØa

      // Landmarks validation - N·ªöI L·ªéNG cho 75%
      if (optimalFace.landmarks.isEmpty) return false;

      // Require basic landmarks for 75% quality (n·ªõi l·ªèng t·ª´ 80%)
      if (!optimalFace.landmarks.containsKey(FaceLandmarkType.leftEye) ||
          !optimalFace.landmarks.containsKey(FaceLandmarkType.rightEye))
        return false;

      // Embedding validation v·ªõi optimal face - N·ªöI L·ªéNG 75%
      await AIModelManager.instance.ensureModelsReady();

      if (_faceEmbedder != null) {
        final embeddingResult = await _faceEmbedder!.getFaceEmbedding(
          imageFile.path,
          faceBox,
        );

        if (!embeddingResult.success) return false;

        final embedding = embeddingResult.embedding;
        if (embedding.length != 192) return false;

        // N·ªõi l·ªèng embedding quality check - 75%
        final embeddingMagnitude = embedding
            .map((e) => e * e)
            .reduce((a, b) => a + b);
        if (embeddingMagnitude < 0.2) return false; // N·ªõi l·ªèng: 0.25 ‚Üí 0.2

        if (embedding.any((e) => e.isNaN) || embedding.any((e) => e.isInfinite))
          return false;

        // Validate embedding variance for quality - N·ªöI L·ªéNG 75%
        final mean = embedding.reduce((a, b) => a + b) / embedding.length;
        final variance =
            embedding
                .map((e) => (e - mean) * (e - mean))
                .reduce((a, b) => a + b) /
            embedding.length;
        if (variance < 0.001) return false;

        // Additional quality checks for 75% standard (n·ªõi l·ªèng)
        final maxValue = embedding.reduce((a, b) => a > b ? a : b);
        final minValue = embedding.reduce((a, b) => a < b ? a : b);
        if ((maxValue - minValue) < 0.4) return false; // N·ªõi l·ªèng: 0.5 ‚Üí 0.4
      }

      return true;
    } catch (e) {
      return false;
    }
  }

  /// ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng khu√¥n m·∫∑t to√†n di·ªán cho ƒëƒÉng k√Ω - B·ªé CENTER POSITION - GI·∫¢M XU·ªêNG 75%
  double _calculateFaceQuality(Face face, InputImage inputImage) {
    final imageSize = inputImage.metadata!.size;
    final faceBox = face.boundingBox;

    double qualityScore = 0.0;

    // 1. Size quality (35% weight) - K√≠ch th∆∞·ªõc khu√¥n m·∫∑t - GI·∫¢M ƒë·∫øn 75%
    final faceRatio = faceBox.width / imageSize.width;
    double sizeScore = 0.0;
    if (faceRatio >= 0.15 && faceRatio <= 0.8) {
      // N·ªõi l·ªèng: 0.18-0.75 ‚Üí 0.15-0.8
      // Size range for 75% registration: 15-80% of image width (n·ªõi l·ªèng t·ª´ 18-75%)
      sizeScore =
          1.0 -
          math.max(0, (0.27 - faceRatio).abs() / 0.27); // N·ªõi l·ªèng: 0.3 ‚Üí 0.27
    }
    qualityScore += sizeScore * 0.35; // Gi·ªØ nguy√™n tr·ªçng s·ªë

    // 2. Pose quality (30% weight) - G√≥c nghi√™ng ƒë·∫ßu - GI·∫¢M ƒë·∫øn 75%
    double poseScore = 0.0;
    final yawAngle =
        face.headEulerAngleY?.abs() ?? 30.0; // N·ªõi l·ªèng: 25.0 ‚Üí 30.0
    final rollAngle =
        face.headEulerAngleZ?.abs() ?? 30.0; // N·ªõi l·ªèng: 25.0 ‚Üí 30.0
    if (yawAngle <= 18.0 && rollAngle <= 18.0) {
      // N·ªõi l·ªèng: 12.0 ‚Üí 18.0
      // N·ªõi l·ªèng pose requirements cho registration 75%
      poseScore =
          1.0 - ((yawAngle + rollAngle) / 36.0); // N·ªõi l·ªèng: 24.0 ‚Üí 36.0
    }
    qualityScore += poseScore * 0.30; // Gi·ªØ nguy√™n tr·ªçng s·ªë

    // 3. CENTER POSITION - B·ªé HO√ÄN TO√ÄN (0% weight)
    // Kh√¥ng c·∫ßn ƒë·∫∑t khu√¥n m·∫∑t ·ªü gi·ªØa khung h√¨nh n·ªØa

    // 4. Landmarks quality (20% weight) - GI·∫¢M y√™u c·∫ßu ƒë·∫øn 75%
    double landmarkScore = 0.0;
    if (face.landmarks.isNotEmpty) {
      // N·ªõi l·ªèng landmarks scoring for 75% quality
      if (face.landmarks.containsKey(FaceLandmarkType.leftEye) &&
          face.landmarks.containsKey(FaceLandmarkType.rightEye) &&
          face.landmarks.containsKey(FaceLandmarkType.noseBase) &&
          face.landmarks.containsKey(FaceLandmarkType.bottomMouth)) {
        landmarkScore =
            1.0; // Full score for complete landmarks (v·∫´n y√™u c·∫ßu 4 landmarks)
      } else if (face.landmarks.containsKey(FaceLandmarkType.leftEye) &&
          face.landmarks.containsKey(FaceLandmarkType.rightEye) &&
          face.landmarks.containsKey(FaceLandmarkType.noseBase)) {
        landmarkScore =
            0.9; // Very good score for 3 key landmarks (n·ªõi l·ªèng t·ª´ 75%)
      } else if (face.landmarks.containsKey(FaceLandmarkType.leftEye) &&
          face.landmarks.containsKey(FaceLandmarkType.rightEye)) {
        landmarkScore = 0.8; // Good score for eye landmarks only
      } else {
        landmarkScore = 0.6; // N·ªõi l·ªèng: 0.5 ‚Üí 0.6 cho some landmarks
      }
    }
    qualityScore += landmarkScore * 0.20; // Gi·ªØ nguy√™n tr·ªçng s·ªë

    // 5. Stability bonus (15% weight) - GI·∫¢M y√™u c·∫ßu ƒë·∫øn 75%
    double stabilityScore = 0.0;
    if (_bestFace != null) {
      final prevBox = _bestFace!.boundingBox;
      final movement = math.sqrt(
        math.pow(faceBox.center.dx - prevBox.center.dx, 2) +
            math.pow(faceBox.center.dy - prevBox.center.dy, 2),
      );
      stabilityScore = math.max(
        0.0,
        1.0 - (movement / 50.0),
      ); // N·ªõi l·ªèng: 30.0 ‚Üí 50.0
    } else {
      stabilityScore =
          0.5; // N·ªõi l·ªèng: 0.3 ‚Üí 0.5 cho initial frame v·ªõi 75% standard
    }
    qualityScore += stabilityScore * 0.15; // Gi·ªØ nguy√™n tr·ªçng s·ªë

    return qualityScore.clamp(0.0, 1.0);
  }

  /// Reset quality tracking variables
  void _resetQualityTracking() {
    _consecutiveGoodFrames = 0;
    _bestFace = null;
    _bestQualityScore = 0.0;
    _qualityResetTimer?.cancel();
    _qualityResetTimer = null;
  }

  /// D·ª´ng ƒëƒÉng k√Ω khu√¥n m·∫∑t
  void _stopFaceRegistration() {
    _scanTimer?.cancel();
    _completionCheckTimer?.cancel();

    // Reset quality tracking khi d·ª´ng
    _resetQualityTracking();

    setState(() {
      _isScanningActive = false;
      _captureCount = 0; // Reset capture count
      _capturedImages.clear(); // Clear captured images
      _instruction = 'ƒêƒÉng k√Ω ƒë√£ d·ª´ng';
    });
  }

  /// Handle logout
  Future<void> _handleLogout() async {
    final shouldLogout = await showDialog<bool>(
      context: context,
      builder:
          (context) => AlertDialog(
            title: const Text('ƒêƒÉng xu·∫•t'),
            content: const Text('B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën ƒëƒÉng xu·∫•t?'),
            actions: [
              TextButton(
                onPressed: () => Navigator.of(context).pop(false),
                child: const Text('H·ªßy'),
              ),
              TextButton(
                onPressed: () => Navigator.of(context).pop(true),
                child: const Text('ƒêƒÉng xu·∫•t'),
              ),
            ],
          ),
    );

    if (shouldLogout == true) {
      await AuthService.logout();
      if (mounted) {
        Navigator.of(context).pushReplacement(
          MaterialPageRoute(
            builder: (context) => LoginScreen(cameras: widget.cameras),
          ),
        );
      }
    }
  }

  @override
  void dispose() {
    _scanTimer?.cancel();
    _completionCheckTimer?.cancel();
    _qualityResetTimer?.cancel();
    _faceDetector.close();

    // Clean up quality tracking
    _resetQualityTracking();

    // Clean up FaceEmbedder resources
    if (_isEmbedderInitialized) {
      // Don't dispose models - they're managed by AIModelManager
    }

    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: const Text('ƒêƒÉng K√Ω Khu√¥n M·∫∑t'),
        backgroundColor: Colors.blue,
        foregroundColor: Colors.white,
        actions: [
          IconButton(
            icon: const Icon(Icons.logout),
            onPressed: _handleLogout,
            tooltip: 'ƒêƒÉng xu·∫•t',
          ),
        ],
      ),
      body: Column(
        children: [
          // Camera view with face detection
          Expanded(
            flex: 2,
            child:
                _isFaceDetectorInitialized
                    ? Container(
                      margin: const EdgeInsets.all(16),
                      decoration: BoxDecoration(
                        borderRadius: BorderRadius.circular(12),
                      ),
                      child: ClipRRect(
                        borderRadius: BorderRadius.circular(12),
                        child: Stack(
                          fit: StackFit.expand,
                          children: [
                            CameraView(
                              key: _cameraKey,
                              cameras: widget.cameras,
                              customPaint: _customPaint,
                              onImage: _processImage,
                              onCaptureImage: _onImageCaptured,
                              initialDirection: CameraLensDirection.front,
                            ),
                            // Loading indicator
                            if (!_modelLoaded)
                              const Positioned(
                                top: 20,
                                left: 0,
                                right: 0,
                                child: Column(
                                  children: [
                                    CircularProgressIndicator(),
                                    SizedBox(height: 8),
                                    Text(
                                      'ƒêang t·∫£i m√¥ h√¨nh nh·∫≠n di·ªán...',
                                      style: TextStyle(
                                        color: Colors.white,
                                        backgroundColor: Colors.black54,
                                        fontWeight: FontWeight.bold,
                                      ),
                                      textAlign: TextAlign.center,
                                    ),
                                  ],
                                ),
                              ),
                            // Instructions and Progress Indicator
                            Positioned(
                              bottom: 0,
                              left: 0,
                              right: 0,
                              child: Container(
                                padding: const EdgeInsets.all(8.0),
                                color: Colors.black54,
                                child: Column(
                                  mainAxisSize: MainAxisSize.min,
                                  children: [
                                    // Progress bar for parallel processing
                                    if (_isProcessing &&
                                        _processingProgress > 0)
                                      Column(
                                        children: [
                                          LinearProgressIndicator(
                                            value: _processingProgress,
                                            backgroundColor: Colors.white24,
                                            valueColor:
                                                const AlwaysStoppedAnimation<
                                                  Color
                                                >(Colors.green),
                                          ),
                                          const SizedBox(height: 4),
                                          Text(
                                            _processingStatus,
                                            style: const TextStyle(
                                              color: Colors.white,
                                              fontSize: 12,
                                              fontWeight: FontWeight.bold,
                                            ),
                                            textAlign: TextAlign.center,
                                          ),
                                          const SizedBox(height: 4),
                                        ],
                                      ),
                                    Text(
                                      _instruction,
                                      textAlign: TextAlign.center,
                                      style: const TextStyle(
                                        color: Colors.white,
                                        fontWeight: FontWeight.bold,
                                      ),
                                    ),
                                  ],
                                ),
                              ),
                            ),
                          ],
                        ),
                      ),
                    )
                    : const Center(child: CircularProgressIndicator()),
          ),
          // Cabinet selection and register button
          Expanded(
            flex: 1,
            child: Padding(
              padding: const EdgeInsets.all(16.0),
              child: Column(
                crossAxisAlignment: CrossAxisAlignment.stretch,
                children: [
                  DropdownButtonFormField<String>(
                    decoration: const InputDecoration(
                      labelText: 'Ch·ªçn t·ªß',
                      border: OutlineInputBorder(),
                    ),
                    value: _selectedCabinetId,
                    items:
                        _cabinets
                            .map(
                              (cabinet) => DropdownMenuItem(
                                value: cabinet.id,
                                child: Text(cabinet.id),
                              ),
                            )
                            .toList(),
                    onChanged: (value) {
                      setState(() {
                        _selectedCabinetId = value;
                      });
                    },
                  ),
                  const SizedBox(height: 16),
                  ElevatedButton(
                    onPressed:
                        _isScanningActive
                            ? _stopFaceRegistration
                            : _startFaceRegistration,
                    style: ElevatedButton.styleFrom(
                      padding: const EdgeInsets.symmetric(vertical: 12),
                      backgroundColor:
                          _isScanningActive ? Colors.red : Colors.blue,
                    ),
                    child: Text(
                      _isScanningActive ? 'D·ª´ng ƒêƒÉng K√Ω' : 'B·∫Øt ƒê·∫ßu ƒêƒÉng K√Ω',
                      style: const TextStyle(color: Colors.white),
                    ),
                  ),
                ],
              ),
            ),
          ),
        ],
      ),
    );
  }

  /// Process images in batches with optimized parallel processing
  Future<List<List<double>>> _processImagesBatch(List<XFile> images) async {
    // Validate image count before processing
    if (images.length != _requiredCaptureCount) {
      // Warning: Processing different number of images than expected
    }

    const int batchSize =
        2; // Reduced from 3 to 2 to avoid memory/timeout issues
    List<List<double>> allEmbeddings = [];

    // Reset progress counter
    _processedImageCount = 0;

    setState(() {
      _processingStatus = 'Kh·ªüi t·∫°o x·ª≠ l√Ω batch...';
      _processingProgress = 0.05;
    });

    for (int i = 0; i < images.length; i += batchSize) {
      final end =
          (i + batchSize < images.length) ? i + batchSize : images.length;
      final batch = images.sublist(i, end);

      setState(() {
        _processingStatus =
            'ƒêang x·ª≠ l√Ω batch ${(i ~/ batchSize) + 1}/${((images.length - 1) ~/ batchSize) + 1}...';
        _processingProgress = 0.1 + (i / images.length) * 0.8;
      });

      // Process batch with improved error handling and retry mechanism
      final batchFutures =
          batch.asMap().entries.map((entry) {
            final batchIndex = entry.key;
            final globalIndex = i + batchIndex;
            final imageFile = entry.value;

            return _processImageForEmbeddingWithRetry(
              imageFile,
              globalIndex,
            ).then((result) {
              // Update progress counter
              _processedImageCount++;
              final progress = _processedImageCount / images.length;
              setState(() {
                _processingProgress = 0.1 + (progress * 0.8);
                _processingStatus =
                    'ƒê√£ x·ª≠ l√Ω $_processedImageCount/${images.length} ·∫£nh...';
              });
              return result;
            });
          }).toList();

      try {
        final batchEmbeddings = await Future.wait(batchFutures);
        allEmbeddings.addAll(batchEmbeddings);
      } catch (e) {
        setState(() {
          _processingStatus = 'L·ªói x·ª≠ l√Ω batch: $e';
          _processingProgress = 0.0;
        });
        throw Exception('Batch processing failed: $e');
      }

      // Small delay between batches to prevent overwhelming the system
      await Future.delayed(const Duration(milliseconds: 100));
    }

    setState(() {
      _processingStatus = 'Ho√†n th√†nh x·ª≠ l√Ω t·∫•t c·∫£ batch!';
      _processingProgress = 0.9;
    });

    return allEmbeddings;
  }

  /// Process individual image with retry mechanism for better reliability
  Future<List<double>> _processImageForEmbeddingWithRetry(
    XFile imageFile,
    int imageIndex,
  ) async {
    const int maxRetries = 2;
    const Duration baseTimeout = Duration(seconds: 15); // Increased timeout

    for (int attempt = 0; attempt < maxRetries; attempt++) {
      try {
        final result = await _processImageForEmbeddingParallel(
          imageFile,
          imageIndex,
        ).timeout(
          baseTimeout,
          onTimeout: () {
            throw Exception(
              'Timeout processing image ${imageIndex + 1} after ${baseTimeout.inSeconds}s',
            );
          },
        );

        return result;
      } catch (e) {
        if (attempt == maxRetries - 1) {
          // Last attempt failed, return a fallback or rethrow
          rethrow;
        }

        // Wait before retry
        await Future.delayed(Duration(milliseconds: 500 * (attempt + 1)));
      }
    }

    throw Exception(
      'Failed to process image ${imageIndex + 1} after $maxRetries attempts',
    );
  }
}

/// Data class for batch processing of images
class BatchProcessingData {
  final List<XFile> images;
  final int startIndex;
  final int endIndex;

  BatchProcessingData({
    required this.images,
    required this.startIndex,
    required this.endIndex,
  });
}

/// Result of batch processing
class BatchProcessingResult {
  final List<List<double>> embeddings;
  final int processedCount;
  final int failedCount;
  final double processingTimeMs;

  BatchProcessingResult({
    required this.embeddings,
    required this.processedCount,
    required this.failedCount,
    required this.processingTimeMs,
  });
}
